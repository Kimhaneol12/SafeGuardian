import os
import numpy as np
import cv2
import joblib
from sklearn.metrics import classification_report
import mediapipe as mp

# -------------------------
# Settings
# -------------------------
VIDEO_PATH = "../sample_video.mp4" # ì˜ìƒ ìœ„ì¹˜ì— ë§ê²Œ ì„¤ì •
FALL_MODEL_PATH = "../model/best_weight/fall_detection.pkl"
FALL_TYPE_MODEL_PATH = "../model/best_weight/fall_type.pkl"
RESULT_SAVE_DIR = "../model/eval_results/manual_test"
RESULT_TEXT_FILE = os.path.join(RESULT_SAVE_DIR, "manual_test_result.txt")

SEQUENCE_LENGTH = 600 

# -------------------------
# ê²°ê³¼ ë””ë ‰í† ë¦¬ ìƒì„±
# -------------------------
os.makedirs(RESULT_SAVE_DIR, exist_ok=True)

# -------------------------
# MediaPipe ì´ˆê¸°í™”
# -------------------------
mp_pose = mp.solutions.pose
pose = mp_pose.Pose(static_image_mode=False,
                    min_detection_confidence=0.5,
                    min_tracking_confidence=0.5)

# -------------------------
# ì˜ìƒ ì²˜ë¦¬
# -------------------------
print(f"â–¶ï¸ ì˜ìƒ ì²˜ë¦¬ ì‹œì‘: {VIDEO_PATH}")
cap = cv2.VideoCapture(VIDEO_PATH)
frames = []

while len(frames) < SEQUENCE_LENGTH:
    ret, frame = cap.read()
    if not ret:
        break
    frame = cv2.resize(frame, (480, 270))
    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
    results = pose.process(frame_rgb)
    if results.pose_landmarks:
        pose_data = [[lm.x, lm.y, lm.z, lm.visibility] for lm in results.pose_landmarks.landmark]
        frames.append(np.array(pose_data).flatten())

cap.release()
pose.close()

if len(frames) < SEQUENCE_LENGTH:
    print(f"âŒ í”„ë ˆì„ ë¶€ì¡±: {len(frames)}í”„ë ˆì„ (ìµœì†Œ {SEQUENCE_LENGTH} í•„ìš”)")
    exit()

X = np.array(frames).reshape(1, SEQUENCE_LENGTH * len(frames[0]))

# -------------------------
# ë‚™ìƒ ì—¬ë¶€ ì˜ˆì¸¡
# -------------------------
clf_fall = joblib.load(FALL_MODEL_PATH)
y_pred_fall = clf_fall.predict(X)[0]
fall_label = "FALL" if y_pred_fall == 1 else "NonFall"

print(f"\nğŸ“Š ë‚™ìƒ ì—¬ë¶€ íŒë‹¨ ê²°ê³¼: {fall_label}")

# -------------------------
# ë‚™ìƒ ìœ í˜• ì˜ˆì¸¡ (FALLì¼ ê²½ìš°)
# -------------------------
fall_type_label = "N/A"
if fall_label == "FALL":
    clf_type = joblib.load(FALL_TYPE_MODEL_PATH)
    y_pred_type = clf_type.predict(X)[0]
    fall_type_label = ["BY", "FY", "SY"][y_pred_type]  # í´ë˜ìŠ¤ ìˆœì„œëŠ” í•™ìŠµ ëª¨ë¸ì— ë”°ë¼ ë‹¤ë¥¼ ìˆ˜ ìˆìŒ

# -------------------------
# ê²°ê³¼ ì €ì¥
# -------------------------
with open(RESULT_TEXT_FILE, "w", encoding="utf-8") as f:
    f.write(f"[Result for video: {VIDEO_PATH}]\n")
    f.write(f"Fall Detection: {fall_label}\n")
    f.write(f"Fall Type: {fall_type_label}\n")

print("\nâœ… ê²°ê³¼ ì €ì¥ ì™„ë£Œ:", RESULT_TEXT_FILE)
